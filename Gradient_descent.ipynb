{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This jupyter notebook goes through different versions of the gradient descent optimization algorithm.\n",
    "\n",
    "The first section is a basic GD for a single variable function, where the analytical gradient of the function (the first derivate) is given.\n",
    "\n",
    "The second section is a GD for a function with two variables, where the analytical expression for the derivate is not given. Here, a numerical function to calculate the gradient is used.\n",
    "\n",
    "The third section is not a true gradient descent, but rather a discreet version of it. A two variable function is given and the algorithm finds the minimum in a discreet 2D-matrix.\n",
    "\n",
    "The fourth section is similar to the second section, but generalized to work with a function of any dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most import python libaries are imported for the notebook. For more information on what\n",
    "# specific modules contain, please reference the appropriate documentation\n",
    "import random\n",
    "import sympy\n",
    "import numpy as np \n",
    "import math as m\n",
    "import plotly as plt\n",
    "import itertools as itools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for single variable, analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The general idea of GD is as follows:\n",
    "#   1) pick a random starting point of your function\n",
    "#   2) calculate the slope (for more than one dimension this is called the gradient) of your function\n",
    "#   3) subtract your gradient from your current point on the function to get a new point\n",
    "#   4) iterate steps 2) and 3) with your new point until your step size falls under you require precision\n",
    "#   or you reach a maximum number of iterations\n",
    "\n",
    "# The starting position for the algorithm is not that important for the number of iterations. Since the\n",
    "# function is smooth, points far away from the minimum result in a bigger step size for the first few steps\n",
    "cur_x = random.randint(-10000,10000) \n",
    "# The learning rate of the GD is a simple constant which scales the gradient. If your learning rate is too big\n",
    "# you might over shoot your minimum and have to re-iterate back and fourth. Think about a balls rolling with too much energy\n",
    "# so it passes through the valley and goes up the slope again.\n",
    "# If your learning rate is too small, you need more iterations to get to your result.\n",
    "rate = 0.1 \n",
    "# The precision can be chosen however close you want to be to your true minimum. Since GD is a approximation algorithm, you\n",
    "# will most likely never get to the true minimum. But you can get a difference of less than 0.000001% with only very few\n",
    "# iterations\n",
    "precision = m.pow(10,-9)\n",
    "previous_step_size = 1 # This is what precision is compared to. If the step size is lower than the precision, we are done.\n",
    "max_iters = 10000 # This is the maximum numbers of iterations after which the loop aborts.\n",
    "iters = 0 # iteration counter\n",
    "# For a single variable function like here, the gradient of the function is equal to the first derivate of the function.\n",
    "# For multi variable functions, the gradient is a vector containing all partial derivates for each arguement of the function.\n",
    "df = lambda x: 2*(x+5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 \n",
      "X value is -2229.0\n",
      "Iteration 2 \n",
      "X value is -1784.2\n",
      "Iteration 3 \n",
      "X value is -1428.3600000000001\n",
      "Iteration 4 \n",
      "X value is -1143.688\n",
      "Iteration 5 \n",
      "X value is -915.9504000000001\n",
      "Iteration 6 \n",
      "X value is -733.7603200000001\n",
      "Iteration 7 \n",
      "X value is -588.0082560000001\n",
      "Iteration 8 \n",
      "X value is -471.4066048000001\n",
      "Iteration 9 \n",
      "X value is -378.12528384000007\n",
      "Iteration 10 \n",
      "X value is -303.50022707200003\n",
      "Iteration 11 \n",
      "X value is -243.80018165760004\n",
      "Iteration 12 \n",
      "X value is -196.04014532608002\n",
      "Iteration 13 \n",
      "X value is -157.832116260864\n",
      "Iteration 14 \n",
      "X value is -127.26569300869122\n",
      "Iteration 15 \n",
      "X value is -102.81255440695297\n",
      "Iteration 16 \n",
      "X value is -83.25004352556238\n",
      "Iteration 17 \n",
      "X value is -67.6000348204499\n",
      "Iteration 18 \n",
      "X value is -55.080027856359926\n",
      "Iteration 19 \n",
      "X value is -45.064022285087944\n",
      "Iteration 20 \n",
      "X value is -37.05121782807036\n",
      "Iteration 21 \n",
      "X value is -30.640974262456286\n",
      "Iteration 22 \n",
      "X value is -25.512779409965027\n",
      "Iteration 23 \n",
      "X value is -21.410223527972022\n",
      "Iteration 24 \n",
      "X value is -18.128178822377617\n",
      "Iteration 25 \n",
      "X value is -15.502543057902093\n",
      "Iteration 26 \n",
      "X value is -13.402034446321675\n",
      "Iteration 27 \n",
      "X value is -11.72162755705734\n",
      "Iteration 28 \n",
      "X value is -10.377302045645873\n",
      "Iteration 29 \n",
      "X value is -9.301841636516698\n",
      "Iteration 30 \n",
      "X value is -8.44147330921336\n",
      "Iteration 31 \n",
      "X value is -7.753178647370687\n",
      "Iteration 32 \n",
      "X value is -7.202542917896549\n",
      "Iteration 33 \n",
      "X value is -6.7620343343172395\n",
      "Iteration 34 \n",
      "X value is -6.409627467453792\n",
      "Iteration 35 \n",
      "X value is -6.127701973963033\n",
      "Iteration 36 \n",
      "X value is -5.902161579170427\n",
      "Iteration 37 \n",
      "X value is -5.721729263336341\n",
      "Iteration 38 \n",
      "X value is -5.577383410669073\n",
      "Iteration 39 \n",
      "X value is -5.461906728535259\n",
      "Iteration 40 \n",
      "X value is -5.369525382828207\n",
      "Iteration 41 \n",
      "X value is -5.295620306262565\n",
      "Iteration 42 \n",
      "X value is -5.236496245010052\n",
      "Iteration 43 \n",
      "X value is -5.189196996008041\n",
      "Iteration 44 \n",
      "X value is -5.151357596806433\n",
      "Iteration 45 \n",
      "X value is -5.121086077445146\n",
      "Iteration 46 \n",
      "X value is -5.096868861956117\n",
      "Iteration 47 \n",
      "X value is -5.077495089564893\n",
      "Iteration 48 \n",
      "X value is -5.061996071651914\n",
      "Iteration 49 \n",
      "X value is -5.049596857321531\n",
      "Iteration 50 \n",
      "X value is -5.039677485857225\n",
      "Iteration 51 \n",
      "X value is -5.03174198868578\n",
      "Iteration 52 \n",
      "X value is -5.025393590948624\n",
      "Iteration 53 \n",
      "X value is -5.020314872758899\n",
      "Iteration 54 \n",
      "X value is -5.016251898207119\n",
      "Iteration 55 \n",
      "X value is -5.013001518565695\n",
      "Iteration 56 \n",
      "X value is -5.010401214852556\n",
      "Iteration 57 \n",
      "X value is -5.0083209718820445\n",
      "Iteration 58 \n",
      "X value is -5.006656777505635\n",
      "Iteration 59 \n",
      "X value is -5.005325422004509\n",
      "Iteration 60 \n",
      "X value is -5.004260337603607\n",
      "Iteration 61 \n",
      "X value is -5.003408270082885\n",
      "Iteration 62 \n",
      "X value is -5.002726616066308\n",
      "Iteration 63 \n",
      "X value is -5.002181292853047\n",
      "Iteration 64 \n",
      "X value is -5.001745034282438\n",
      "Iteration 65 \n",
      "X value is -5.00139602742595\n",
      "Iteration 66 \n",
      "X value is -5.0011168219407605\n",
      "Iteration 67 \n",
      "X value is -5.000893457552609\n",
      "Iteration 68 \n",
      "X value is -5.000714766042087\n",
      "Iteration 69 \n",
      "X value is -5.00057181283367\n",
      "Iteration 70 \n",
      "X value is -5.000457450266936\n",
      "Iteration 71 \n",
      "X value is -5.000365960213548\n",
      "Iteration 72 \n",
      "X value is -5.000292768170839\n",
      "Iteration 73 \n",
      "X value is -5.000234214536671\n",
      "Iteration 74 \n",
      "X value is -5.000187371629337\n",
      "Iteration 75 \n",
      "X value is -5.000149897303469\n",
      "Iteration 76 \n",
      "X value is -5.000119917842776\n",
      "Iteration 77 \n",
      "X value is -5.000095934274221\n",
      "Iteration 78 \n",
      "X value is -5.000076747419376\n",
      "Iteration 79 \n",
      "X value is -5.000061397935501\n",
      "Iteration 80 \n",
      "X value is -5.000049118348401\n",
      "Iteration 81 \n",
      "X value is -5.000039294678721\n",
      "Iteration 82 \n",
      "X value is -5.000031435742977\n",
      "Iteration 83 \n",
      "X value is -5.000025148594381\n",
      "Iteration 84 \n",
      "X value is -5.000020118875505\n",
      "Iteration 85 \n",
      "X value is -5.0000160951004045\n",
      "Iteration 86 \n",
      "X value is -5.000012876080324\n",
      "Iteration 87 \n",
      "X value is -5.000010300864259\n",
      "Iteration 88 \n",
      "X value is -5.0000082406914075\n",
      "Iteration 89 \n",
      "X value is -5.000006592553126\n",
      "Iteration 90 \n",
      "X value is -5.0000052740425005\n",
      "Iteration 91 \n",
      "X value is -5.000004219234\n",
      "Iteration 92 \n",
      "X value is -5.0000033753872\n",
      "Iteration 93 \n",
      "X value is -5.00000270030976\n",
      "Iteration 94 \n",
      "X value is -5.000002160247808\n",
      "Iteration 95 \n",
      "X value is -5.000001728198247\n",
      "Iteration 96 \n",
      "X value is -5.000001382558597\n",
      "Iteration 97 \n",
      "X value is -5.000001106046878\n",
      "Iteration 98 \n",
      "X value is -5.000000884837503\n",
      "Iteration 99 \n",
      "X value is -5.000000707870003\n",
      "Iteration 100 \n",
      "X value is -5.000000566296002\n",
      "Iteration 101 \n",
      "X value is -5.000000453036802\n",
      "Iteration 102 \n",
      "X value is -5.000000362429441\n",
      "Iteration 103 \n",
      "X value is -5.000000289943553\n",
      "Iteration 104 \n",
      "X value is -5.000000231954842\n",
      "Iteration 105 \n",
      "X value is -5.000000185563874\n",
      "Iteration 106 \n",
      "X value is -5.0000001484510985\n",
      "Iteration 107 \n",
      "X value is -5.0000001187608785\n",
      "Iteration 108 \n",
      "X value is -5.000000095008703\n",
      "Iteration 109 \n",
      "X value is -5.0000000760069625\n",
      "Iteration 110 \n",
      "X value is -5.00000006080557\n",
      "Iteration 111 \n",
      "X value is -5.0000000486444565\n",
      "Iteration 112 \n",
      "X value is -5.000000038915565\n",
      "Iteration 113 \n",
      "X value is -5.000000031132452\n",
      "Iteration 114 \n",
      "X value is -5.000000024905962\n",
      "Iteration 115 \n",
      "X value is -5.000000019924769\n",
      "Iteration 116 \n",
      "X value is -5.000000015939816\n",
      "Iteration 117 \n",
      "X value is -5.000000012751853\n",
      "Iteration 118 \n",
      "X value is -5.000000010201482\n",
      "Iteration 119 \n",
      "X value is -5.0000000081611855\n",
      "Iteration 120 \n",
      "X value is -5.000000006528948\n",
      "Iteration 121 \n",
      "X value is -5.000000005223159\n",
      "Iteration 122 \n",
      "X value is -5.000000004178527\n",
      "Iteration 123 \n",
      "X value is -5.000000003342821\n",
      "The local minimum occurs at  -5.000000003342821\n",
      "Probably the true minimum is at  -5.0\n"
     ]
    }
   ],
   "source": [
    "while previous_step_size > precision and iters < max_iters:\n",
    "    prev_x = cur_x # Store current x value in prev_x.\n",
    "    cur_x = cur_x - rate * df(prev_x) # This is step 2) and 3).\n",
    "    previous_step_size = abs(cur_x - prev_x) # How much have we moved in this step.\n",
    "    iters = iters+1 # iteration count\n",
    "    print(\"Iteration\",iters,\"\\nX value is\",cur_x) # Print iterations\n",
    "\n",
    "# Print end result plus a reasonable guess at to what the true minimum might have been.\n",
    "print(\"The local minimum occurs at \", cur_x)\n",
    "print(\"Probably the true minimum is at \", round(cur_x, abs(int(m.log10(precision)))-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have found a local minimum at \n",
      "-4.999999951897902 with a delta of \n",
      "9.81675185585118e-10 running \n",
      "1147 iterations\n"
     ]
    }
   ],
   "source": [
    "print('We have found a local minimum at \\n{} with a delta of \\n{} running \\n{} iterations'.format(cur_x, previous_step_size, iters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for two variables, non-analytical, continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this section, there are two main problems:\n",
    "# 1) we need two variables, so we need can't use floats for our data types\n",
    "# 2) we don't have an analytical expression which we can evaluate for the gradient.\n",
    "\n",
    "# Sets the two variable function\n",
    "def f(x1, x2):\n",
    "    return (x1-18)**2+(x2-2)**2\n",
    "\n",
    "# Define individual partial differentials. Both functions return the gradient triangle of the function for one argument\n",
    "# by changing only one of the arguements and not altering the other.\n",
    "# The function is evaluated two times, once +0.001 and once -0.001 the current point on the axis in question. Then the slope\n",
    "# is calculated by simply subtracting both values and dividing by the distance between them (0.002)\n",
    "def pdiffx1(position):\n",
    "    return (f(position[0].item()+10**-3, position[1].item()) - f(position[0].item()-10**-3, position[1].item()))/(2*10**-3)\n",
    "\n",
    "def pdiffx2(position):\n",
    "    return (f(position[0].item(), position[1].item()+10**-3) - f(position[0].item(), position[1].item()-10**-3))/(2*10**-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current position now is not a point, but rather a set of coordinates, which are here supply in form of a numpy-column-vector\n",
    "# Starting position is set to a random point\n",
    "cur_pos = np.matrix([random.randint(-10000, 10000),random.randint(-10000, 10000)]).transpose() \n",
    "rate = 0.1 # see first section\n",
    "precision = 10**-9 # see first section\n",
    "step = np.matrix([1, 1]) # see first section. Note, that our step is now also a vector, instead of a float value\n",
    "max_iters = 10000 # see first section\n",
    "iters = 0 # see first section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \n",
      "X value is\n",
      " [[4552.39999989]\n",
      " [ 274.8       ]]\n",
      "Iteration 1 \n",
      "X value is\n",
      " [[3645.51999985]\n",
      " [ 220.23999992]]\n",
      "Iteration 2 \n",
      "X value is\n",
      " [[2920.01599973]\n",
      " [ 176.59199995]]\n",
      "Iteration 3 \n",
      "X value is\n",
      " [[2339.61279966]\n",
      " [ 141.67359996]]\n",
      "Iteration 4 \n",
      "X value is\n",
      " [[1875.29023962]\n",
      " [ 113.73887996]]\n",
      "Iteration 5 \n",
      "X value is\n",
      " [[1503.83219171]\n",
      " [  91.39110398]]\n",
      "Iteration 6 \n",
      "X value is\n",
      " [[1206.66575338]\n",
      " [  73.51288319]]\n",
      "Iteration 7 \n",
      "X value is\n",
      " [[968.93260271]\n",
      " [ 59.21030655]]\n",
      "Iteration 8 \n",
      "X value is\n",
      " [[778.74608217]\n",
      " [ 47.76824524]]\n",
      "Iteration 9 \n",
      "X value is\n",
      " [[626.59686574]\n",
      " [ 38.61459619]]\n",
      "Iteration 10 \n",
      "X value is\n",
      " [[504.8774926 ]\n",
      " [ 31.29167695]]\n",
      "Iteration 11 \n",
      "X value is\n",
      " [[407.50199408]\n",
      " [ 25.43334156]]\n",
      "Iteration 12 \n",
      "X value is\n",
      " [[329.60159527]\n",
      " [ 20.74667325]]\n",
      "Iteration 13 \n",
      "X value is\n",
      " [[267.28127621]\n",
      " [ 16.9973386 ]]\n",
      "Iteration 14 \n",
      "X value is\n",
      " [[217.42502097]\n",
      " [ 13.99787088]]\n",
      "Iteration 15 \n",
      "X value is\n",
      " [[177.54001678]\n",
      " [ 11.5982967 ]]\n",
      "Iteration 16 \n",
      "X value is\n",
      " [[145.63201342]\n",
      " [  9.67863736]]\n",
      "Iteration 17 \n",
      "X value is\n",
      " [[120.10561074]\n",
      " [  8.14290989]]\n",
      "Iteration 18 \n",
      "X value is\n",
      " [[99.68448859]\n",
      " [ 6.91432791]]\n",
      "Iteration 19 \n",
      "X value is\n",
      " [[83.34759087]\n",
      " [ 5.93146233]]\n",
      "Iteration 20 \n",
      "X value is\n",
      " [[70.2780727 ]\n",
      " [ 5.14516986]]\n",
      "Iteration 21 \n",
      "X value is\n",
      " [[59.82245816]\n",
      " [ 4.51613589]]\n",
      "Iteration 22 \n",
      "X value is\n",
      " [[51.45796653]\n",
      " [ 4.01290871]]\n",
      "Iteration 23 \n",
      "X value is\n",
      " [[44.76637322]\n",
      " [ 3.61032697]]\n",
      "Iteration 24 \n",
      "X value is\n",
      " [[39.41309858]\n",
      " [ 3.28826158]]\n",
      "Iteration 25 \n",
      "X value is\n",
      " [[35.13047886]\n",
      " [ 3.03060926]]\n",
      "Iteration 26 \n",
      "X value is\n",
      " [[31.70438309]\n",
      " [ 2.82448741]]\n",
      "Iteration 27 \n",
      "X value is\n",
      " [[28.96350647]\n",
      " [ 2.65958993]]\n",
      "Iteration 28 \n",
      "X value is\n",
      " [[26.77080518]\n",
      " [ 2.52767194]]\n",
      "Iteration 29 \n",
      "X value is\n",
      " [[25.01664414]\n",
      " [ 2.42213755]]\n",
      "Iteration 30 \n",
      "X value is\n",
      " [[23.61331531]\n",
      " [ 2.33771004]]\n",
      "Iteration 31 \n",
      "X value is\n",
      " [[22.49065225]\n",
      " [ 2.27016803]]\n",
      "Iteration 32 \n",
      "X value is\n",
      " [[21.5925218 ]\n",
      " [ 2.21613443]]\n",
      "Iteration 33 \n",
      "X value is\n",
      " [[20.87401744]\n",
      " [ 2.17290754]]\n",
      "Iteration 34 \n",
      "X value is\n",
      " [[20.29921395]\n",
      " [ 2.13832603]]\n",
      "Iteration 35 \n",
      "X value is\n",
      " [[19.83937116]\n",
      " [ 2.11066083]]\n",
      "Iteration 36 \n",
      "X value is\n",
      " [[19.47149693]\n",
      " [ 2.08852866]]\n",
      "Iteration 37 \n",
      "X value is\n",
      " [[19.17719754]\n",
      " [ 2.07082293]]\n",
      "Iteration 38 \n",
      "X value is\n",
      " [[18.94175803]\n",
      " [ 2.05665834]]\n",
      "Iteration 39 \n",
      "X value is\n",
      " [[18.75340643]\n",
      " [ 2.04532667]]\n",
      "Iteration 40 \n",
      "X value is\n",
      " [[18.60272514]\n",
      " [ 2.03626134]]\n",
      "Iteration 41 \n",
      "X value is\n",
      " [[18.48218011]\n",
      " [ 2.02900907]]\n",
      "Iteration 42 \n",
      "X value is\n",
      " [[18.38574409]\n",
      " [ 2.02320726]]\n",
      "Iteration 43 \n",
      "X value is\n",
      " [[18.30859527]\n",
      " [ 2.01856581]]\n",
      "Iteration 44 \n",
      "X value is\n",
      " [[18.24687622]\n",
      " [ 2.01485264]]\n",
      "Iteration 45 \n",
      "X value is\n",
      " [[18.19750097]\n",
      " [ 2.01188212]]\n",
      "Iteration 46 \n",
      "X value is\n",
      " [[18.15800078]\n",
      " [ 2.00950569]]\n",
      "Iteration 47 \n",
      "X value is\n",
      " [[18.12640062]\n",
      " [ 2.00760455]]\n",
      "Iteration 48 \n",
      "X value is\n",
      " [[18.1011205 ]\n",
      " [ 2.00608364]]\n",
      "Iteration 49 \n",
      "X value is\n",
      " [[18.0808964 ]\n",
      " [ 2.00486691]]\n",
      "Iteration 50 \n",
      "X value is\n",
      " [[18.06471712]\n",
      " [ 2.00389353]]\n",
      "Iteration 51 \n",
      "X value is\n",
      " [[18.0517737 ]\n",
      " [ 2.00311483]]\n",
      "Iteration 52 \n",
      "X value is\n",
      " [[18.04141896]\n",
      " [ 2.00249186]]\n",
      "Iteration 53 \n",
      "X value is\n",
      " [[18.03313517]\n",
      " [ 2.00199349]]\n",
      "Iteration 54 \n",
      "X value is\n",
      " [[18.02650813]\n",
      " [ 2.00159479]]\n",
      "Iteration 55 \n",
      "X value is\n",
      " [[18.02120651]\n",
      " [ 2.00127583]]\n",
      "Iteration 56 \n",
      "X value is\n",
      " [[18.0169652 ]\n",
      " [ 2.00102067]]\n",
      "Iteration 57 \n",
      "X value is\n",
      " [[18.01357216]\n",
      " [ 2.00081653]]\n",
      "Iteration 58 \n",
      "X value is\n",
      " [[18.01085773]\n",
      " [ 2.00065323]]\n",
      "Iteration 59 \n",
      "X value is\n",
      " [[18.00868618]\n",
      " [ 2.00052258]]\n",
      "Iteration 60 \n",
      "X value is\n",
      " [[18.00694895]\n",
      " [ 2.00041806]]\n",
      "Iteration 61 \n",
      "X value is\n",
      " [[18.00555916]\n",
      " [ 2.00033445]]\n",
      "Iteration 62 \n",
      "X value is\n",
      " [[18.00444733]\n",
      " [ 2.00026756]]\n",
      "Iteration 63 \n",
      "X value is\n",
      " [[18.00355786]\n",
      " [ 2.00021405]]\n",
      "Iteration 64 \n",
      "X value is\n",
      " [[18.00284629]\n",
      " [ 2.00017124]]\n",
      "Iteration 65 \n",
      "X value is\n",
      " [[18.00227703]\n",
      " [ 2.00013699]]\n",
      "Iteration 66 \n",
      "X value is\n",
      " [[18.00182162]\n",
      " [ 2.00010959]]\n",
      "Iteration 67 \n",
      "X value is\n",
      " [[18.0014573 ]\n",
      " [ 2.00008767]]\n",
      "Iteration 68 \n",
      "X value is\n",
      " [[18.00116584]\n",
      " [ 2.00007014]]\n",
      "Iteration 69 \n",
      "X value is\n",
      " [[18.00093267]\n",
      " [ 2.00005611]]\n",
      "Iteration 70 \n",
      "X value is\n",
      " [[18.00074614]\n",
      " [ 2.00004489]]\n",
      "Iteration 71 \n",
      "X value is\n",
      " [[18.00059691]\n",
      " [ 2.00003591]]\n",
      "Iteration 72 \n",
      "X value is\n",
      " [[18.00047753]\n",
      " [ 2.00002873]]\n",
      "Iteration 73 \n",
      "X value is\n",
      " [[18.00038202]\n",
      " [ 2.00002298]]\n",
      "Iteration 74 \n",
      "X value is\n",
      " [[18.00030562]\n",
      " [ 2.00001839]]\n",
      "Iteration 75 \n",
      "X value is\n",
      " [[18.00024449]\n",
      " [ 2.00001471]]\n",
      "Iteration 76 \n",
      "X value is\n",
      " [[18.0001956 ]\n",
      " [ 2.00001177]]\n",
      "Iteration 77 \n",
      "X value is\n",
      " [[18.00015648]\n",
      " [ 2.00000941]]\n",
      "Iteration 78 \n",
      "X value is\n",
      " [[18.00012518]\n",
      " [ 2.00000753]]\n",
      "Iteration 79 \n",
      "X value is\n",
      " [[18.00010014]\n",
      " [ 2.00000602]]\n",
      "Iteration 80 \n",
      "X value is\n",
      " [[18.00008012]\n",
      " [ 2.00000482]]\n",
      "Iteration 81 \n",
      "X value is\n",
      " [[18.00006409]\n",
      " [ 2.00000386]]\n",
      "Iteration 82 \n",
      "X value is\n",
      " [[18.00005127]\n",
      " [ 2.00000308]]\n",
      "Iteration 83 \n",
      "X value is\n",
      " [[18.00004102]\n",
      " [ 2.00000247]]\n",
      "Iteration 84 \n",
      "X value is\n",
      " [[18.00003282]\n",
      " [ 2.00000197]]\n",
      "Iteration 85 \n",
      "X value is\n",
      " [[18.00002625]\n",
      " [ 2.00000158]]\n",
      "Iteration 86 \n",
      "X value is\n",
      " [[18.000021  ]\n",
      " [ 2.00000126]]\n",
      "Iteration 87 \n",
      "X value is\n",
      " [[18.0000168 ]\n",
      " [ 2.00000101]]\n",
      "Iteration 88 \n",
      "X value is\n",
      " [[18.00001344]\n",
      " [ 2.00000081]]\n",
      "Iteration 89 \n",
      "X value is\n",
      " [[18.00001075]\n",
      " [ 2.00000065]]\n",
      "Iteration 90 \n",
      "X value is\n",
      " [[18.0000086 ]\n",
      " [ 2.00000052]]\n",
      "Iteration 91 \n",
      "X value is\n",
      " [[18.00000688]\n",
      " [ 2.00000041]]\n",
      "Iteration 92 \n",
      "X value is\n",
      " [[18.00000551]\n",
      " [ 2.00000033]]\n",
      "Iteration 93 \n",
      "X value is\n",
      " [[18.0000044 ]\n",
      " [ 2.00000026]]\n",
      "Iteration 94 \n",
      "X value is\n",
      " [[18.00000352]\n",
      " [ 2.00000021]]\n",
      "Iteration 95 \n",
      "X value is\n",
      " [[18.00000282]\n",
      " [ 2.00000017]]\n",
      "Iteration 96 \n",
      "X value is\n",
      " [[18.00000226]\n",
      " [ 2.00000014]]\n",
      "Iteration 97 \n",
      "X value is\n",
      " [[18.0000018 ]\n",
      " [ 2.00000011]]\n",
      "Iteration 98 \n",
      "X value is\n",
      " [[18.00000144]\n",
      " [ 2.00000009]]\n",
      "Iteration 99 \n",
      "X value is\n",
      " [[18.00000115]\n",
      " [ 2.00000007]]\n",
      "Iteration 100 \n",
      "X value is\n",
      " [[18.00000092]\n",
      " [ 2.00000006]]\n",
      "Iteration 101 \n",
      "X value is\n",
      " [[18.00000074]\n",
      " [ 2.00000004]]\n",
      "Iteration 102 \n",
      "X value is\n",
      " [[18.00000059]\n",
      " [ 2.00000004]]\n",
      "Iteration 103 \n",
      "X value is\n",
      " [[18.00000047]\n",
      " [ 2.00000003]]\n",
      "Iteration 104 \n",
      "X value is\n",
      " [[18.00000038]\n",
      " [ 2.00000002]]\n",
      "Iteration 105 \n",
      "X value is\n",
      " [[18.0000003 ]\n",
      " [ 2.00000002]]\n",
      "Iteration 106 \n",
      "X value is\n",
      " [[18.00000024]\n",
      " [ 2.00000001]]\n",
      "Iteration 107 \n",
      "X value is\n",
      " [[18.00000019]\n",
      " [ 2.00000001]]\n",
      "Iteration 108 \n",
      "X value is\n",
      " [[18.00000015]\n",
      " [ 2.00000001]]\n",
      "Iteration 109 \n",
      "X value is\n",
      " [[18.00000012]\n",
      " [ 2.00000001]]\n",
      "Iteration 110 \n",
      "X value is\n",
      " [[18.0000001 ]\n",
      " [ 2.00000001]]\n",
      "Iteration 111 \n",
      "X value is\n",
      " [[18.00000008]\n",
      " [ 2.        ]]\n",
      "Iteration 112 \n",
      "X value is\n",
      " [[18.00000006]\n",
      " [ 2.        ]]\n",
      "Iteration 113 \n",
      "X value is\n",
      " [[18.00000005]\n",
      " [ 2.        ]]\n",
      "Iteration 114 \n",
      "X value is\n",
      " [[18.00000004]\n",
      " [ 2.        ]]\n",
      "Iteration 115 \n",
      "X value is\n",
      " [[18.00000003]\n",
      " [ 2.        ]]\n",
      "Iteration 116 \n",
      "X value is\n",
      " [[18.00000003]\n",
      " [ 2.        ]]\n",
      "Iteration 117 \n",
      "X value is\n",
      " [[18.00000002]\n",
      " [ 2.        ]]\n",
      "Iteration 118 \n",
      "X value is\n",
      " [[18.00000002]\n",
      " [ 2.        ]]\n",
      "Iteration 119 \n",
      "X value is\n",
      " [[18.00000001]\n",
      " [ 2.        ]]\n",
      "Iteration 120 \n",
      "X value is\n",
      " [[18.00000001]\n",
      " [ 2.        ]]\n",
      "Iteration 121 \n",
      "X value is\n",
      " [[18.00000001]\n",
      " [ 2.        ]]\n",
      "Iteration 122 \n",
      "X value is\n",
      " [[18.00000001]\n",
      " [ 2.        ]]\n",
      "Iteration 123 \n",
      "X value is\n",
      " [[18.00000001]\n",
      " [ 2.        ]]\n",
      "Iteration 124 \n",
      "X value is\n",
      " [[18.]\n",
      " [ 2.]]\n",
      "Iteration 125 \n",
      "X value is\n",
      " [[18.]\n",
      " [ 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Since we can't compare a vector to a scalar, we need to first calculate the norm of that vector. This represents the total \"length\"\n",
    "# of that vector.\n",
    "while np.linalg.norm(step) > precision and iters < max_iters:\n",
    "    prev_pos = cur_pos # save current position\n",
    "    # Since our position is the form of a vector, we can provide the gradient as a vector too and just subtract the two\n",
    "    # with the inbuild numpy function for matrices. Notice, that numpy automatically returns row vectors instead of column-\n",
    "    # vectors, so we have to transpose the gradient before subtracting it\n",
    "    cur_pos = cur_pos - rate * np.matrix([pdiffx1(cur_pos), pdiffx2(cur_pos)]).transpose()\n",
    "    # Since both positions are numpy matrices, the step is simply the difference\n",
    "    step = abs(prev_pos-cur_pos)\n",
    "    print(\"Iteration\",iters,\"\\nX value is\\n\",cur_pos) #Print iterations\n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for two variables, non analytical, discreet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalu(x, y):\n",
    "    return (x-6)**2+(y-8)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4     5     6     7     8     9\n",
      "0  None  None  None  None  None  None  None  None  None  None\n",
      "1  None  None  None  None  None  None  None  None  None  None\n",
      "2  None  None  None  None  None  None  None  None  None  None\n",
      "3  None  None  None  None  None  None  None  None  None  None\n",
      "4  None  None  None  None    20    13     8  None  None  None\n",
      "5  None  None  None  None    17    10     5  None  None  None\n",
      "6  None  None  None  None    16     9     4  None  None  None\n",
      "7  None  None  None  None  None  None  None  None  None  None\n",
      "8  None  None  None  None  None  None  None  None  None  None\n",
      "9  None  None  None  None  None  None  None  None  None  None\n",
      "      0     1     2     3     4     5     6     7     8     9\n",
      "0  None  None  None  None  None  None  None  None  None  None\n",
      "1  None  None  None  None  None  None  None  None  None  None\n",
      "2  None  None  None  None  None  None  None  None  None  None\n",
      "3  None  None  None  None  None  None  None  None  None  None\n",
      "4  None  None  None  None    20    13     8  None  None  None\n",
      "5  None  None  None  None    17    10     5     2  None  None\n",
      "6  None  None  None  None    16     9     4     1  None  None\n",
      "7  None  None  None  None  None    10     5     2  None  None\n",
      "8  None  None  None  None  None  None  None  None  None  None\n",
      "9  None  None  None  None  None  None  None  None  None  None\n",
      "      0     1     2     3     4     5     6     7     8     9\n",
      "0  None  None  None  None  None  None  None  None  None  None\n",
      "1  None  None  None  None  None  None  None  None  None  None\n",
      "2  None  None  None  None  None  None  None  None  None  None\n",
      "3  None  None  None  None  None  None  None  None  None  None\n",
      "4  None  None  None  None    20    13     8  None  None  None\n",
      "5  None  None  None  None    17    10     5     2     1  None\n",
      "6  None  None  None  None    16     9     4     1     0  None\n",
      "7  None  None  None  None  None    10     5     2     1  None\n",
      "8  None  None  None  None  None  None  None  None  None  None\n",
      "9  None  None  None  None  None  None  None  None  None  None\n",
      "      0     1     2     3     4     5     6     7     8     9\n",
      "0  None  None  None  None  None  None  None  None  None  None\n",
      "1  None  None  None  None  None  None  None  None  None  None\n",
      "2  None  None  None  None  None  None  None  None  None  None\n",
      "3  None  None  None  None  None  None  None  None  None  None\n",
      "4  None  None  None  None    20    13     8  None  None  None\n",
      "5  None  None  None  None    17    10     5     2     1     2\n",
      "6  None  None  None  None    16     9     4     1     0     1\n",
      "7  None  None  None  None  None    10     5     2     1     2\n",
      "8  None  None  None  None  None  None  None  None  None  None\n",
      "9  None  None  None  None  None  None  None  None  None  None\n",
      "finished\n",
      "minimum found at x1 = 6, x2 = 8, z = 0 with 20 evaluations compared to 100\n"
     ]
    }
   ],
   "source": [
    "# This section is a bit different from the others and closer to a use case problem (although not a very good one)\n",
    "# The premise is, that instead of a continous function, we have a discreet result space. What this means is,\n",
    "# that our function arguements can't take every real number, but only certain values. Maybe we want to determine the optiomal\n",
    "# number of solar panels to install. With the first algorithm we might get 5.2335 solar panels, which is hard to install.\n",
    "# So this sections tries to emulate the method behind gradient descent for a discreet scenario.\n",
    "\n",
    "# Problems to think about:\n",
    "# Since we can only access certain values for arguements, simply using the normal\n",
    "# cur_pos = cur_pos - rate * gradient\n",
    "# won't really be usable. Instead, think about what gradient descent does. It looks at the space surrounding your\n",
    "# point and takes a step towards the direction with the steepest descent. Ideally, our algorithm should emulate\n",
    "# that behaviour\n",
    "\n",
    "# The following describes this algorithm for a 2D-result space\n",
    "np.set_printoptions(precision=3) # This is simply setting formatting parameters for numpy\n",
    "mat_GD = np.array([[None]*10]*10) # fill result space\n",
    "x1 = round(len(mat_GD)/2) # set initial point to the center of the matrix\n",
    "x2 = round(len(mat_GD)/2) # set initial point to the center of the matrix\n",
    "# The surrounding of a point is simply each combination of one step back or one step forward or no steps for all \n",
    "# axis of our result space. This can be achieved with a nested loop:\n",
    "# for i in [-1, 0, 1]:\n",
    "#     for j in [-1, 0, 1]:\n",
    "#         print((i,j))\n",
    "#\n",
    "# will return all relative cells around your current cell. The product function of the module itertools does exactly that.\n",
    "permut = list(itools.product([-1, 0, 1], repeat=2)) # get all relative steps to access your adjacent points\n",
    "finished = False # start loop control variable\n",
    "current_minimum = evalu(x1, x2)\n",
    "num_of_evals = 0\n",
    "while not finished:\n",
    "    i = 0\n",
    "    \"\"\"This loop will iterate over all adjacent cells in the matrix and evalutate the function at those points if it\n",
    "    hasn't been evaluated before.\"\"\"\n",
    "    for step in permut: # For every possible step ...\n",
    "        if mat_GD[x1+step[0], x2+step[1]]==None: # ... we check if we already have that value ...\n",
    "            mat_GD[x1+step[0], x2+step[1]] = evalu(x1+step[0], x2+step[1]) # ... and if not, we calculate if.\n",
    "            num_of_evals +=1\n",
    "        else: i += 1\n",
    "        if mat_GD[x1+step[0], x2+step[1]] <= current_minimum: # Then we compare to our current minimum ...\n",
    "            # ... and if the minimum around us is different from our current spot, we remember the step and save the new\n",
    "            # minimum.\n",
    "            current_minimum = mat_GD[x1+step[0], x2+step[1]]\n",
    "            new_x1 = x1+step[0]\n",
    "            new_x2 = x2+step[1]\n",
    "    # Here we print the current matrix for each iterations, so we can see the steps we took each iterations\n",
    "    print(pd.DataFrame(mat_GD))\n",
    "    # When we have looked at all the surrrounding cells, we check if our current coordinates are the same, as the coordinates\n",
    "    # of the minimum. If yes, we found the local minimum, else we take a step towards the new minimum\n",
    "    if x1 == new_x1 and x2 == new_x2:\n",
    "        finished = True\n",
    "    else:\n",
    "        x1 = new_x1\n",
    "        x2 = new_x2\n",
    "print('finished')\n",
    "print('minimum found at x1 = {}, x2 = {}, z = {} with {} evaluations compared to {}'.format(x1, x2, mat_GD[x1,x2], num_of_evals, mat_GD.size))\n",
    "\n",
    "# This algorithm lacks two important properties:\n",
    "# 1) It can only be used for 2 dimensional functions. This should be fairly simple to edit.\n",
    "# 2) It lacks a proper edge detection, which is much more serious. Ideally, the algorithm would check,\n",
    "# if the adjacent cells exists or are out of bounds and would not evaluate them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(mat_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for multivariable, non-analytic, continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section is the most advanced form of the algorithm in this notebook. It is a GD, for a function\n",
    "# with any number of arguements, with no analytical expression require. To use this algorithm, one only needs the definition\n",
    "# of the function (can be a complex simulation) and the number of arguements one wants to look at.\n",
    "# Until the sections is cleaned up into an actual module, one need only to change the function f and the number of arguements.\n",
    "\n",
    "# Sets the function to optimize\n",
    "def f(args):    \n",
    "    return (args[0]-1293.234)**2+(args[1]-2)**2+(args[2]-3)**2+(args[3]-5)**2+(args[4]-2000)**2+(args[5]+5634)**2\n",
    "\n",
    "# Calculates the gradient for a function f at a certain position, which is supplied as a list. The return value is also a list,\n",
    "# where each value is the partial derivate of the function for the variable at the same index.\n",
    "def grad(f, position):\n",
    "    grad = []\n",
    "    for ID in range(len(position)):\n",
    "        # For each arguement, we copy the position list twice...\n",
    "        delta_pos = position.copy()\n",
    "        delta_neg = position.copy()\n",
    "        # ... and change the arguement in question, once positive and once negative.\n",
    "        delta_pos[ID] = delta_pos[ID] + 10**-9     \n",
    "        delta_neg[ID] = delta_neg[ID] - 10**-9\n",
    "        # Then we evaluate, calculate the difference and divide by the distance to get a slope approximation.\n",
    "        grad.append((f(delta_pos)-f(delta_neg))/(2*10**-9))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \n",
      "X value is\n",
      " [-2708.7925033569336, -3468.751724243164, -3477.6924209594727, -3477.6924209594727, -2279.639060974121, -6861.746128082275]\n",
      "Iteration 1 \n",
      "X value is\n",
      " [-305.9802608489995, -1385.5693893432617, -1390.039737701416, -1387.8045635223389, 289.69365787506104, -6124.97683930397]\n",
      "Iteration 2 \n",
      "X value is\n",
      " [653.4682555198665, -552.9670076370239, -554.0845947265625, -552.12881731987, 1315.9180028438568, -5830.283093631268]\n",
      "Iteration 3 \n",
      "X value is\n",
      " [1037.3594207763667, -219.99590414762497, -219.85620576143265, -217.84804145991802, 1726.3693237751722, -5712.464967176318]\n",
      "Iteration 4 \n",
      "X value is\n",
      " [1190.8792160525913, -86.80222406238317, -86.14302230253816, -84.13922357559204, 1890.54548657313, -5665.364783156663]\n",
      "Iteration 5 \n",
      "X value is\n",
      " [1252.2908449014644, -33.52038645371795, -32.65709408279508, -30.655478143133223, 1956.2173705040477, -5646.5376971331425]\n",
      "Iteration 6 \n",
      "X value is\n",
      " [1276.8564786952916, -12.20819710707292, -11.26277736457996, -9.262116394354962, 1982.486669773236, -5639.011753531493]\n",
      "Iteration 7 \n",
      "X value is\n",
      " [1286.682875458238, -3.683270209337934, -2.7051086575811514, -0.7048399069462921, 1992.9945566005626, -5636.003365326276]\n",
      "Iteration 8 \n",
      "X value is\n",
      " [1290.6135083440781, -0.2733045661516371, 0.7179537093106756, 2.718064719458196, 1997.1977799699216, -5634.80081260221]\n",
      "Iteration 9 \n",
      "X value is\n",
      " [1292.185786651627, 1.0906779607735189, 2.0871816403468966, 4.087225504205888, 1998.8790942577152, -5634.320111656494]\n",
      "Iteration 10 \n",
      "X value is\n",
      " [1292.8147080998806, 1.6362712646424598, 2.634872732825327, 4.634890217785253, 1999.5516305510378, -5634.127959345765]\n",
      "Iteration 11 \n",
      "X value is\n",
      " [1293.0662805627421, 1.8545085095846474, 2.8539491231873324, 4.853956108213003, 1999.820649374922, -5634.051149637171]\n",
      "Iteration 12 \n",
      "X value is\n",
      " [1293.1669111582653, 1.9418034100595243, 2.9415796551847837, 4.941582451894094, 1999.9282586131087, -5634.020446223401]\n",
      "Iteration 13 \n",
      "X value is\n",
      " [1293.2071640379406, 1.9767213671269728, 2.976631865017387, 4.9766329836419425, 1999.9713029900256, -5634.008173040411]\n",
      "Iteration 14 \n",
      "X value is\n",
      " [1293.2232654449322, 1.9906885479893779, 2.9906527471940207, 4.990653194610696, 1999.9885210139073, -5634.003267038016]\n",
      "Iteration 15 \n",
      "X value is\n",
      " [1293.2297061098607, 1.9962754196610504, 2.996261099339343, 4.996261278302139, 1999.9954083327232, -5634.001305944529]\n",
      "Iteration 16 \n",
      "X value is\n",
      " [1293.2322824167002, 1.9985101680499953, 2.998504439921407, 4.99850451150753, 1999.998163303954, -5634.0005220297735]\n",
      "Iteration 17 \n",
      "X value is\n",
      " [1293.2333129557815, 1.9994040672939681, 2.999401776042729, 4.9994018046772934, 1999.9992653099273, -5634.000208672787]\n",
      "Iteration 18 \n",
      "X value is\n",
      " [1293.2337251779531, 1.9997616269471579, 2.999760710446782, 4.999760721900628, 1999.9997061193092, -5634.000083413503]\n",
      "Iteration 19 \n",
      "X value is\n",
      " [1293.2338900694374, 1.9999046507906986, 2.999904284190592, 4.9999042887721314, 1999.999882445859, -5634.000033343171]\n",
      "Iteration 20 \n",
      "X value is\n",
      " [1293.2339560270773, 1.999961860321013, 2.999961713680989, 4.999961715513604, 1999.9999529775976, -5634.000013328382]\n",
      "Iteration 21 \n",
      "X value is\n",
      " [1293.2339824105518, 1.9999847441302987, 2.9999846854742964, 4.999984686207342, 1999.9999811907408, -5634.000005327801]\n",
      "Iteration 22 \n",
      "X value is\n",
      " [1293.2339929641091, 1.9999938976528768, 2.999993874190479, 4.999993874483697, 1999.9999924761769, -5634.0000021297]\n",
      "Iteration 23 \n",
      "X value is\n",
      " [1293.233997185599, 1.9999975590614536, 2.999997549676496, 4.9999975497937825, 1999.999996990423, -5634.0000008513125]\n",
      "Iteration 24 \n",
      "X value is\n",
      " [1293.2339988742217, 1.9999990236247027, 2.99999901987072, 4.9999990199176345, 1999.99999879615, -5634.000000340298]\n",
      "Iteration 25 \n",
      "X value is\n",
      " [1293.2339995496816, 1.9999996094499295, 2.999999607948337, 4.999999607967102, 1999.9999995184523, -5634.000000136029]\n",
      "Iteration 26 \n",
      "X value is\n",
      " [1293.2339998198697, 1.9999998437799913, 2.999999843179354, 4.999999843186861, 1999.999999807378, -5634.000000054375]\n"
     ]
    }
   ],
   "source": [
    "num_of_args = 6\n",
    "# Since we don't need a visual representation for our result space, we can simply use pythons inbuild lists instead of\n",
    "# numpys matrices\n",
    "# Much of the rest is the same as in second section except we iterate over each arguement.\n",
    "cur_pos = [random.randint(-10000, 10000)]*num_of_args\n",
    "rate = 0.3\n",
    "precision = 10**-6 #This tells us when to stop the algorithm\n",
    "step = [1]*len(cur_pos)\n",
    "max_iters = 10000 # maximum number of iterations\n",
    "iters = 0 #iteration counter\n",
    "\n",
    "while np.linalg.norm(step) > precision and iters < max_iters:\n",
    "    prev_pos = cur_pos.copy()\n",
    "    for ID in range(len(cur_pos)):        \n",
    "        cur_pos[ID] = cur_pos[ID] - rate * grad(f, cur_pos)[ID]\n",
    "        step[ID] = abs(prev_pos[ID]-cur_pos[ID])\n",
    "    print(\"Iteration\",iters,\"\\nX value is\\n\",cur_pos) #Print iterations\n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
