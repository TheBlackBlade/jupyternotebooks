{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sympy\n",
    "import numpy as np\n",
    "import math as m\n",
    "import plotly as plt\n",
    "import itertools as itools\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for single variable, analytic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_x = random.randint(-1000,1000) # The algorithm starts at x=3\n",
    "rate = 0.01 # Learning rate\n",
    "precision = m.pow(10,-9) #This tells us when to stop the algorithm\n",
    "previous_step_size = 1 #\n",
    "max_iters = 10000 # maximum number of iterations\n",
    "iters = 0 #iteration counter\n",
    "df = lambda x: 2*(x+5) #Gradient of our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while previous_step_size > precision and iters < max_iters:\n",
    "    prev_x = cur_x #Store current x value in prev_x\n",
    "    cur_x = cur_x - rate * df(prev_x) #Grad descent\n",
    "    previous_step_size = abs(cur_x - prev_x) #Change in x\n",
    "    iters = iters+1 #iteration count\n",
    "    print(\"Iteration\",iters,\"\\nX value is\",cur_x) #Print iterations\n",
    "    \n",
    "print(\"The local minimum occurs at \", cur_x)\n",
    "print(\"Probably the true minimum is at \", round(cur_x, abs(int(m.log10(precision)))-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('We have found a local minimum at \\n{} with a delta of \\n{} running \\n{} iterations'.format(cur_x, previous_step_size, iters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for two variables, non-analytical, continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x1, x2):\n",
    "    return (x1-18)**2+(x2-2)**2\n",
    "\n",
    "def pdiffx1(position):\n",
    "    return (f(position[0].item()+10**-3, position[1].item()) - f(position[0].item()-10**-3, position[1].item()))/(2*10**-3)\n",
    "\n",
    "def pdiffx2(position):\n",
    "    return (f(position[0].item(), position[1].item()+10**-3) - f(position[0].item(), position[1].item()-10**-3))/(2*10**-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_pos = np.matrix([random.randint(-10000, 10000),random.randint(-10000, 10000)]).transpose()\n",
    "rate = 0.1 # Learning rate\n",
    "precision = 10**-5 #This tells us when to stop the algorithm\n",
    "step = np.matrix([1, 1]) #\n",
    "max_iters = 10000 # maximum number of iterations\n",
    "iters = 0 #iteration counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while np.linalg.norm(step) > precision and iters < max_iters:\n",
    "    prev_pos = cur_pos\n",
    "    cur_pos = cur_pos - rate * np.matrix([pdiffx1(cur_pos), pdiffx2(cur_pos)]).transpose()\n",
    "    step = abs(prev_pos-cur_pos)\n",
    "    print(\"Iteration\",iters,\"\\nX value is\\n\",cur_pos) #Print iterations\n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for two variables, non analytical, discreet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalu(x, y):\n",
    "    return (x-6)**2+(y-8)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "mat_GD = np.array([[None]*10]*10) # fill result space\n",
    "x1 = round(len(mat_GD)/2) # set initial point\n",
    "x2 = round(len(mat_GD)/2) # set initial point\n",
    "permut = list(itools.product([-1, 0, 1], repeat=2)) # get all relativ steps around your point\n",
    "finished = False\n",
    "current_minimum = evalu(x1, x2)\n",
    "num_of_evals = 0\n",
    "while not finished:\n",
    "    i = 0\n",
    "    \"\"\"This loop will iterate over all adjacent cells in the matrix and evalutate the function at those points.\"\"\"\n",
    "    for step in permut:\n",
    "        if mat_GD[x1+step[0], x2+step[1]]==None:\n",
    "            mat_GD[x1+step[0], x2+step[1]] = evalu(x1+step[0], x2+step[1])\n",
    "            num_of_evals +=1\n",
    "        else: i += 1\n",
    "        if mat_GD[x1+step[0], x2+step[1]] <= current_minimum:\n",
    "            current_minimum = mat_GD[x1+step[0], x2+step[1]]\n",
    "            new_x1 = x1+step[0]\n",
    "            new_x2 = x2+step[1]\n",
    "    print(pd.DataFrame(mat_GD))\n",
    "    if x1 == new_x1 and x2 == new_x2:\n",
    "        finished = True\n",
    "    else:\n",
    "        x1 = new_x1\n",
    "        x2 = new_x2\n",
    "print('finished')\n",
    "print('minimum found at x1 = {}, x2 = {}, z = {} with {} evaluations compared to {}'.format(x1, x2, mat_GD[x1,x2], num_of_evals, mat_GD.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(mat_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GD for multivariable, non-analytic, continous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(args):    \n",
    "    return (args[0]-18)**2+(args[1]-2)**2+(args[2]-3)**2\n",
    "\n",
    "def pdiff(f, position):\n",
    "    grad = []\n",
    "    for ID in range(len(position)):        \n",
    "        delta_pos = position.copy()\n",
    "        delta_neg = position.copy()\n",
    "        delta_pos[ID] = delta_pos[ID] + 10**-5      \n",
    "        delta_neg[ID] = delta_neg[ID] - 10**-5\n",
    "        grad.append((f(delta_pos)-f(delta_neg)/(2*10**-5)))\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1499.8700029999195, -1499.870002999915, -1499.8700029999152]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [18, 2, 3]\n",
    "pdiff(f, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
